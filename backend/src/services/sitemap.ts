import axios from 'axios';
import pkg from 'xml2js';
const { Parser } = pkg;


export interface SitemapLink {
    url: string;
    lastModified?: string;
    priority?: string;
}

export class SitemapService {
    /**
     * Bir URL'in sitemap.xml dosyasƒ±nƒ± bulmaya √ßalƒ±≈üƒ±r
     * √ñnce /sitemap.xml, sonra /sitemap_index.xml, sonra robots.txt kontrol eder
     */
    async findAndParseSitemap(rootUrl: string): Promise<SitemapLink[]> {
        const enableSitemap = process.env.ENABLE_SITEMAP === 'true';
        if (!enableSitemap) {
            console.log('üìç Sitemap desteƒüi kapalƒ± (.env ENABLE_SITEMAP=false)');
            return [];
        }

        console.log('üìç Sitemap aranƒ±yor...');

        // URL'i temizle (trailing slash kaldƒ±r)
        const baseUrl = rootUrl.replace(/\/$/, '');

        // Sitemap √ße≈üitleri
        const sitemapUrls = [
            `${baseUrl}/sitemap.xml`,
            `${baseUrl}/sitemap_index.xml`,
            `${baseUrl}/sitemap-index.xml`,
            `${baseUrl}/sitemap/sitemap.xml`
        ];

        // √ñnce sitemap.xml dene
        for (const sitemapUrl of sitemapUrls) {
            try {
                const links = await this.fetchAndParseSitemap(sitemapUrl);
                if (links.length > 0) {
                    console.log(`‚úÖ Sitemap bulundu: ${sitemapUrl} (${links.length} URL)`);
                    return links;
                }
            } catch (error) {
                // Devam et, ba≈üka sitemap dene
            }
        }

        // robots.txt'den sitemap konumunu √∂ƒürenmeyi dene
        try {
            const robotsUrl = `${baseUrl}/robots.txt`;
            const robotsLinks = await this.findSitemapFromRobots(robotsUrl);
            if (robotsLinks.length > 0) {
                console.log(`‚úÖ Sitemap robots.txt'den bulundu (${robotsLinks.length} URL)`);
                return robotsLinks;
            }
        } catch (error) {
            // Sorun deƒüil
        }

        console.log('‚ö†Ô∏è Sitemap bulunamadƒ±, klasik scraping devam edecek');
        return [];
    }

    private async fetchAndParseSitemap(sitemapUrl: string): Promise<SitemapLink[]> {
        const response = await axios.get(sitemapUrl, {
            timeout: 10000,
            headers: {
                'User-Agent': 'Mozilla/5.0 (compatible; AI-Chatbot-Bot/1.0)'
            }
        });

        const xmlData = response.data;
        const parser = new Parser();
        const result = await parser.parseStringPromise(xmlData);

        const links: SitemapLink[] = [];

        // Normal sitemap (urlset)
        if (result.urlset && result.urlset.url) {
            for (const urlEntry of result.urlset.url) {
                links.push({
                    url: urlEntry.loc[0],
                    lastModified: urlEntry.lastmod?.[0],
                    priority: urlEntry.priority?.[0]
                });
            }
        }

        // Sitemap index (sitemapindex)
        if (result.sitemapindex && result.sitemapindex.sitemap) {
            for (const sitemapEntry of result.sitemapindex.sitemap) {
                const childSitemapUrl = sitemapEntry.loc[0];
                try {
                    const childLinks = await this.fetchAndParseSitemap(childSitemapUrl);
                    links.push(...childLinks);
                } catch (error) {
                    console.warn(`‚ö†Ô∏è Child sitemap fetch failed: ${childSitemapUrl}`);
                }
            }
        }

        return links;
    }

    private async findSitemapFromRobots(robotsUrl: string): Promise<SitemapLink[]> {
        const response = await axios.get(robotsUrl, {
            timeout: 5000,
            headers: {
                'User-Agent': 'Mozilla/5.0 (compatible; AI-Chatbot-Bot/1.0)'
            }
        });

        const robotsTxt = response.data;
        const sitemapLines = robotsTxt.split('\n')
            .filter((line: string) => line.toLowerCase().startsWith('sitemap:'));

        for (const line of sitemapLines) {
            const sitemapUrl = line.split(':', 2)[1].trim();
            try {
                const links = await this.fetchAndParseSitemap(sitemapUrl);
                if (links.length > 0) {
                    return links;
                }
            } catch (error) {
                // Devam
            }
        }

        return [];
    }

    /**
     * Sitemap'ten gelen URL'leri "deƒüerli" sayfalara filtreler
     * Hizmet/√úr√ºn/Fiyat detay sayfalarƒ±nƒ± tanƒ±maya √ßalƒ±≈üƒ±r
     */
    filterValuableUrls(sitemapLinks: SitemapLink[], rootUrl: string): { text: string; href: string }[] {
        const valuablePatterns = [
            /\/(hizmet|service|tedavi|treatment|urun|product|menu|yemek|food|dish)/i,
            /\/(fiyat|price|pricing)/i,
            /\/(oda|room|konaklama|accommodation)/i,
            /\/(paket|package|kampanya|offer)/i
        ];

        const noisePatterns = [
            /\/(blog|haber|news|makale|article)/i,
            /\/(kategori|category|etiket|tag)/i,
            /\/(sepet|cart|checkout|giris|login|kayit|register)/i,
            /\/(sayfa|page)\//i  // Pagination
        ];

        return sitemapLinks
            .filter(link => {
                const url = link.url.toLowerCase();

                // G√ºr√ºlt√º kontrol√º
                if (noisePatterns.some(pattern => pattern.test(url))) {
                    return false;
                }

                // Ana sayfa deƒüil
                if (url === rootUrl || url === `${rootUrl}/`) {
                    return false;
                }

                // Deƒüerli pattern'lerden birine uyuyor mu?
                return valuablePatterns.some(pattern => pattern.test(url));
            })
            .map(link => ({
                text: this.extractTitleFromUrl(link.url),
                href: link.url
            }))
            .slice(0, 150); // Max 150 link
    }

    private extractTitleFromUrl(url: string): string {
        // URL'den slug √ßƒ±kar ve ba≈ülƒ±k haline getir
        try {
            const urlObj = new URL(url);
            const pathParts = urlObj.pathname.split('/').filter(p => p);
            const lastPart = pathParts[pathParts.length - 1] || '';
            return lastPart
                .replace(/-/g, ' ')
                .replace(/_/g, ' ')
                .split(' ')
                .map(word => word.charAt(0).toUpperCase() + word.slice(1))
                .join(' ');
        } catch {
            return 'Unknown';
        }
    }
}
